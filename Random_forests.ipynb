{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Going for a [walk](https://xcitech.github.io/tutorials/heroku_tutorial/) in the (random) forest.*\n",
    "\n",
    "# Random forests\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import *\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "Recall that low_memory=False commands the module to read in the file before assigning data types. Not using it now, may later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('cleaned_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Summary column- not useful at this point- and auto-generated indexing column ('Unnamed: 0')\n",
    "cleaned_df = cleaned_df.drop(['Unnamed: 0'], axis=1)\n",
    "cleaned_df = cleaned_df.drop(['summary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>category</th>\n",
       "      <th>condition</th>\n",
       "      <th>price</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>lululemon</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>new</td>\n",
       "      <td>37.95</td>\n",
       "      <td>ebay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>lululemon</td>\n",
       "      <td>bras</td>\n",
       "      <td>new</td>\n",
       "      <td>15.00</td>\n",
       "      <td>ebay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lululemon</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>new</td>\n",
       "      <td>69.00</td>\n",
       "      <td>ebay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>lululemon</td>\n",
       "      <td>bottoms</td>\n",
       "      <td>new</td>\n",
       "      <td>22.50</td>\n",
       "      <td>ebay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>lululemon</td>\n",
       "      <td>tops</td>\n",
       "      <td>new</td>\n",
       "      <td>14.99</td>\n",
       "      <td>ebay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand category condition  price  site\n",
       "0  lululemon  bottoms       new  37.95  ebay\n",
       "1  lululemon     bras       new  15.00  ebay\n",
       "2  lululemon  bottoms       new  69.00  ebay\n",
       "3  lululemon  bottoms       new  22.50  ebay\n",
       "4  lululemon     tops       new  14.99  ebay"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "Here, I take categorical data and convert it to arbitrary numerical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "cleaned_df = pd.concat([cleaned_df,pd.get_dummies(cleaned_df['brand'],drop_first=True,prefix=\"brand\")],axis=1)\n",
    "cleaned_df = pd.concat([cleaned_df,pd.get_dummies(cleaned_df['condition'],drop_first=True,prefix=\"condition\")],axis=1)\n",
    "cleaned_df = pd.concat([cleaned_df,pd.get_dummies(cleaned_df['category'],drop_first=True,prefix=\"category\")],axis=1)\n",
    "cleaned_df = pd.concat([cleaned_df,pd.get_dummies(cleaned_df['site'],drop_first=True,prefix=\"site\")],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then remove the original columns, which all contain strings. The model can't use those, thus the bother with OHE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.drop(['brand', 'condition', 'category', 'site'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/testing split\n",
    "\n",
    "I am setting the random state (equivalent to set.seed in the R universe) to 29- which means the results will be the same each time I run the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_df.drop('price', axis=1), \n",
    "                                                                            cleaned_df['price'], test_size = 0.2, \n",
    "                                                                            random_state = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (170432, 15)\n",
      "Training Labels Shape: (170432,)\n",
      "Testing Features Shape: (42608, 15)\n",
      "Testing Labels Shape: (42608,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For another time, perhaps- dealing with time series, or [cyclical features](http://blog.davidkaleko.com/feature-engineering-cyclical-features.html).*\n",
    "\n",
    "Moving on...\n",
    "\n",
    "### Establish baseline\n",
    "\n",
    "The baseline is the error I would get if I simply predicted the historical average sale price for all items. If I can reduce the error by using my model, that's a good sign the approach is valid.\n",
    "\n",
    "Very confusingly, [this](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0) tutorial calls the independent variables *and* the df 'features'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error: $ 107.79\n"
     ]
    }
   ],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "\n",
    "baseline_preds = y_train # Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds)\n",
    "print('Average baseline error: $', round(np.mean(baseline_errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=29, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 29)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting to the withheld data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: $ 42.67\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the Test Set\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error: $', round(np.mean(errors), 2))\n",
    "\n",
    "#r2 = r2_score(y_test, predictions)\n",
    "#print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hot damn, an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(y_test)\n",
    "df1= pd.DataFrame.reset_index(df1) # reset for ease of merge\n",
    "del df1['index'] # the prior index isn't useful here\n",
    "df1.columns = ['ytrue']\n",
    "\n",
    "df2 = pd.DataFrame(predictions)\n",
    "df2.columns = ['ypred']\n",
    "\n",
    "rf_train_test_df = pd.merge(df1, df2, df3, right_index=True, left_index=True) # merge based on index\n",
    "rf_train_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(X_test.site_poshmark)\n",
    "df3= pd.DataFrame.reset_index(df3)\n",
    "del df3['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_test_df = pd.merge(rf_train_test_df, df3, right_index=True, left_index=True) # merge based on index\n",
    "rf_train_test_df.head()\n",
    "pd.DataFrame.to_csv(rf_train_test_df, 'rf_train_test_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle that\n",
    "I messed up *a lot* here. If you're adapting this tutorial, pay attention to all the little details that come next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6252812783640533\n"
     ]
    }
   ],
   "source": [
    "# My model is called 'rf' (as you see above)- whatever you called your model, substitute that in for 'rf', below.\n",
    "# Don't change anything else unless you really want to.\n",
    "with open('model.pkl', 'wb') as fid:\n",
    "    pickle.dump(rf, fid,2)  \n",
    "\n",
    "# Load the model from disk\n",
    "loaded_model = pickle.load(open('model.pkl', 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "# The script below gives the same value- r^2:\n",
    "#r2 = r2_score(y_test, predictions)\n",
    "#print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning: following [this](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74) tutorial\n",
    "\n",
    "I could probably get that r^2 value of 63% up just a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 1000,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 29,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn documentation tells us the most important settings are the number of trees in the forest (n_estimators) and the number of features considered for splitting at each leaf node (max_features).\n",
    "\n",
    "I'm going to try to change the first two of these:\n",
    "\n",
    "- n_estimators = number of trees in the foreset\n",
    "- max_features = max number of features considered for splitting a node\n",
    "- max_depth = max number of levels in each decision tree\n",
    "- min_samples_split = min number of data points placed in a node before the node is split\n",
    "- min_samples_leaf = min number of data points allowed in a leaf node\n",
    "- bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "bootstrap = [True, False] # Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# Search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.fit.best_params_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: $ 42.67\n",
      "0.6252659565602762\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the Test Set\n",
    "predictions = rf_200_s_t.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error: $', round(np.mean(errors), 2))\n",
    "\n",
    "r2_cv = r2_score(y_test, predictions)\n",
    "print(r2_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning appears to have done basically nothing here. Perhaps I'll give XGBoost a go?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on..\n",
    "\n",
    "We need to create our...\n",
    "\n",
    "### Feature vector \n",
    "\n",
    "...of the exact same dimension as our training set. To convert our user input into dummy variables, we should save a dict of the the dummy variables. Later we can populate our feature vector for prediction using this dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataframe with only the dummy variables. Mine was called 'cleaned_df' and my dependent variable is 'price'.\n",
    "\n",
    "cat = cleaned_df.drop('price',axis=1)\n",
    "index_dict = dict(zip(cat.columns,range(cat.shape[1])))\n",
    "\n",
    "with open('cat', 'wb') as fid:\n",
    "    pickle.dump(index_dict, fid, 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213040, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may, at this point, want to open the troubleshooting_scratchpad.ipynb for instructions on how to use your pickled model to talk to the Flask app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, but not least...\n",
    "## Evaluation of model performance\n",
    "\n",
    "Super, model has run, but is it decent? To check, I'm calculating accuracy by substracting the mean average percentage error (MAPE) from 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.42 %.\n"
     ]
    }
   ],
   "source": [
    "mape = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eBay and poshmark random forest models\n",
    "I'm running these for ease of coding my application- the performance is fine when I load in two pickled models. Trying to code a binary site selection doesn't yield proper results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_edit = cleaned_df[(cleaned_df.site == 'poshmark')].index\n",
    "cleaned_df.drop(cleaned_df_edit, inplace=True)\n",
    "pd.DataFrame.to_csv(cleaned_df, 'cleaned_df_ebay.csv')\n",
    "# Same procedure to subset the poshmark dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_ebay = pd.read_csv('cleaned_df_ebay.csv')\n",
    "cleaned_df_pm = pd.read_csv('cleaned_df_pm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "cleaned_df_ebay = pd.concat([cleaned_df_ebay,pd.get_dummies(cleaned_df_ebay['brand'],drop_first=True,prefix=\"brand\")],axis=1)\n",
    "cleaned_df_ebay = pd.concat([cleaned_df_ebay,pd.get_dummies(cleaned_df_ebay['condition'],drop_first=True,prefix=\"condition\")],axis=1)\n",
    "cleaned_df_ebay = pd.concat([cleaned_df_ebay,pd.get_dummies(cleaned_df_ebay['category'],drop_first=True,prefix=\"category\")],axis=1)\n",
    "cleaned_df_ebay = pd.concat([cleaned_df_ebay,pd.get_dummies(cleaned_df_ebay['site'],drop_first=True,prefix=\"site\")],axis=1)\n",
    "\n",
    "cleaned_df_pm = pd.concat([cleaned_df_pm,pd.get_dummies(cleaned_df_pm['brand'],drop_first=True,prefix=\"brand\")],axis=1)\n",
    "cleaned_df_pm = pd.concat([cleaned_df_pm,pd.get_dummies(cleaned_df_pm['condition'],drop_first=True,prefix=\"condition\")],axis=1)\n",
    "cleaned_df_pm = pd.concat([cleaned_df_pm,pd.get_dummies(cleaned_df_pm['category'],drop_first=True,prefix=\"category\")],axis=1)\n",
    "cleaned_df_pm = pd.concat([cleaned_df_pm,pd.get_dummies(cleaned_df_pm['site'],drop_first=True,prefix=\"site\")],axis=1)\n",
    "\n",
    "cleaned_df_ebay.drop(['brand', 'condition', 'category', 'site'],axis=1,inplace=True)\n",
    "cleaned_df_pm.drop(['brand', 'condition', 'category', 'site'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df_ebay = cleaned_df_ebay.dropna()\n",
    "cleaned_df_pm = cleaned_df_pm.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, the eBay model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_df_ebay.drop('price', axis=1), \n",
    "                                                                            cleaned_df_ebay['price'], test_size = 0.2, \n",
    "                                                                            random_state = 29)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 29)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "# Pickle that!\n",
    "with open('ebmodel.pkl', 'wb') as fid:\n",
    "    pickle.dump(rf, fid,2)  \n",
    "    \n",
    "# A lovely feature vector\n",
    "cateb = cleaned_df_ebay.drop('price',axis=1)\n",
    "index_dict = dict(zip(cateb.columns,range(cateb.shape[1])))\n",
    "\n",
    "with open('cateb', 'wb') as fid:\n",
    "    pickle.dump(index_dict, fid, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And now, the poshmark model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_df_pm.drop('price', axis=1), \n",
    "                                                                            cleaned_df_pm['price'], test_size = 0.2, \n",
    "                                                                            random_state = 29)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 29)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "# Pickle that!\n",
    "with open('pmmodel.pkl', 'wb') as fid:\n",
    "    pickle.dump(rf, fid,2)  \n",
    "    \n",
    "# A lovely feature vector\n",
    "catpm = cleaned_df_pm.drop('price',axis=1)\n",
    "index_dict = dict(zip(catpm.columns,range(catpm.shape[1])))\n",
    "\n",
    "with open('catpm', 'wb') as fid:\n",
    "    pickle.dump(index_dict, fid, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can XGBoost beat the random forest?\n",
    "\n",
    "I'm looking to see if XGBoost gives me superior model accuracy and a better r^2.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import csv as csv\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn import *\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lindsay/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', alpha=10, learning_rate = 0.2, max_depth = 15)\n",
    "\n",
    "xg_reg.fit(X_train, y_train)\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6252776760499661\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, preds)\n",
    "print(r2) # close, but..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
