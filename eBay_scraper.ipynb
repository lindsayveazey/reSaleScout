{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A document in progress showing my scraper development.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules\n",
    "*(Always do this step before running any other code chunks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import certifi\n",
    "import urllib3\n",
    "import pandas as pd \n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New listings (brand = lululemon)\n",
    "\n",
    "Here, I specify the URL for **sold/completed** listings of **lululemon** brand clothing in **New** condition. (It's all in the link). Reminder to check the [robot.txt](https://www.ebay.com/robots.txt) for the site you want to scrape- don't get blocked as a bot!\n",
    "\n",
    "I'm also identifying the page for BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpage = 'https://www.ebay.com/sch/i.html?_nkw=lululemon&LH_ItemCondition=1500|1000&LH_Complete=1&rt=nc&LH_Sold=1'\n",
    "\n",
    "http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())\n",
    "r = http.request('GET', urlpage)\n",
    "page = urllib.request.urlopen(urlpage).read()\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "# print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using the chunk below for testing snippets of code- ignore or use it as a scratchpad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "<class 'bs4.element.ResultSet'>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# For testing\n",
    "item_containers = soup.find_all('div', {'class': 's-item__info clearfix'})\n",
    "print(len(item_containers)) # should be about 4 dozen\n",
    "# item_containers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the scraper\n",
    "On this site, there are 48 listings per page. We are starting to scrape at page 1; I want to scrape 500 pages. I'm retrieving 1) title/item details in a messy HTML chunk, to be cleaned later; 2) price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23904\n",
      "23904\n"
     ]
    }
   ],
   "source": [
    "page_num = 1\n",
    "\n",
    "# Create lists to store the scraped information\n",
    "summary = []\n",
    "price = []\n",
    "\n",
    "while page_num<=500:\n",
    "    html = requests.get(urlpage.format(page_num)).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for item in soup.select('div.s-item__info.clearfix'):\n",
    "        if item.select_one(\"h3.s-item__title\"):\n",
    "            summary.append(item.select_one(\"h3.s-item__title\").text)\n",
    "        if item.select_one(\"span.s-item__price\"):\n",
    "            price.append(item.select_one(\"span.s-item__price\").text)\n",
    "\n",
    "    page_num=page_num+1\n",
    "\n",
    "# Check the results\n",
    "print(len(summary))\n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23904 entries, 0 to 23903\n",
      "Data columns (total 2 columns):\n",
      "Summary    23904 non-null object\n",
      "Price      23904 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 373.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sold  Sep 16, 2019Lululemon red padded Sports ...</td>\n",
       "      <td>$13.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sold  Sep 16, 2019NWT $128.00 Lululemon On The...</td>\n",
       "      <td>$64.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sold  Sep 16, 2019Lululemon Skinny Will Pant 2...</td>\n",
       "      <td>$48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sold  Sep 16, 2019Lululemon Hotty Hot Short Sz...</td>\n",
       "      <td>$41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sold  Sep 16, 2019Ladies Lululemon Tank Flowy ...</td>\n",
       "      <td>$16.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary   Price\n",
       "0  Sold  Sep 16, 2019Lululemon red padded Sports ...  $13.49\n",
       "1  Sold  Sep 16, 2019NWT $128.00 Lululemon On The...  $64.00\n",
       "2  Sold  Sep 16, 2019Lululemon Skinny Will Pant 2...  $48.00\n",
       "3  Sold  Sep 16, 2019Lululemon Hotty Hot Short Sz...  $41.00\n",
       "4  Sold  Sep 16, 2019Ladies Lululemon Tank Flowy ...  $16.00"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_eBay_lululemon_df = pd.DataFrame({'Summary': summary, 'Price': price})\n",
    "print(new_eBay_lululemon_df.info())\n",
    "new_eBay_lululemon_df.head()\n",
    "\n",
    "# Ew that looks like a lot of memory usage but I'll, uh, deal with it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-owned listings (brand = lululemon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the workflow again, with less commentary. In this instance, I am applying the scraper to retrieve **sold/completed** listings of **lululemon** brand clothing in **Pre-owned** condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpage = 'https://www.ebay.com/sch/i.html?_nkw=lululemon&LH_Complete=1&LH_Sold=1&rt=nc&LH_ItemCondition=3000'\n",
    "\n",
    "http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())\n",
    "r = http.request('GET', urlpage)\n",
    "page = urllib.request.urlopen(urlpage).read()\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23904\n",
      "23904\n"
     ]
    }
   ],
   "source": [
    "page_num = 1\n",
    "\n",
    "# Create lists to store the scraped information\n",
    "summary = []\n",
    "price = []\n",
    "\n",
    "while page_num<=500:\n",
    "    html = requests.get(urlpage.format(page_num)).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for item in soup.select('div.s-item__info.clearfix'):\n",
    "        if item.select_one(\"h3.s-item__title\"):\n",
    "            summary.append(item.select_one(\"h3.s-item__title\").text)\n",
    "        if item.select_one(\"span.s-item__price\"):\n",
    "            price.append(item.select_one(\"span.s-item__price\").text)\n",
    "\n",
    "    page_num=page_num+1\n",
    "\n",
    "# Check the results\n",
    "print(len(summary))\n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23904 entries, 0 to 23903\n",
      "Data columns (total 2 columns):\n",
      "Summary    23904 non-null object\n",
      "Price      23904 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 373.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sold  Sep 16, 2019lululemon Quarter Legnth Jac...</td>\n",
       "      <td>$25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sold  Sep 16, 2019Lululemon Commission Warpstr...</td>\n",
       "      <td>$35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sold  Sep 16, 2019EUC Lululemon Pace Setter Sk...</td>\n",
       "      <td>$44.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sold  Sep 16, 2019Lululemon Knot Gonna Fly Tee...</td>\n",
       "      <td>$29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sold  Sep 16, 2019Lululemon Core Shorts Men’s ...</td>\n",
       "      <td>$34.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary   Price\n",
       "0  Sold  Sep 16, 2019lululemon Quarter Legnth Jac...  $25.00\n",
       "1  Sold  Sep 16, 2019Lululemon Commission Warpstr...  $35.00\n",
       "2  Sold  Sep 16, 2019EUC Lululemon Pace Setter Sk...  $44.99\n",
       "3  Sold  Sep 16, 2019Lululemon Knot Gonna Fly Tee...  $29.99\n",
       "4  Sold  Sep 16, 2019Lululemon Core Shorts Men’s ...  $34.00"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po_eBay_lululemon_df = pd.DataFrame({'Summary': summary, 'Price': price})\n",
    "print(po_eBay_lululemon_df.info())\n",
    "po_eBay_lululemon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New listings (brand = Reformation)\n",
    "\n",
    "The scraper is retrieving **sold/completed** listings of **Reformation** brand clothing in **New** condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpage = 'https://www.ebay.com/sch/i.html?_nkw=reformation&_sacat=15724&LH_TitleDesc=0&LH_Sold=1&LH_Complete=1&rt=nc&LH_ItemCondition=1000%7C1500'\n",
    "\n",
    "http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())\n",
    "r = http.request('GET', urlpage)\n",
    "page = urllib.request.urlopen(urlpage).read()\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632\n",
      "1632\n"
     ]
    }
   ],
   "source": [
    "page_num = 1\n",
    "\n",
    "# Create lists to store the scraped information\n",
    "summary = []\n",
    "price = []\n",
    "\n",
    "while page_num<=35: # Only ~2000 listings\n",
    "    html = requests.get(urlpage.format(page_num)).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for item in soup.select('div.s-item__info.clearfix'):\n",
    "        if item.select_one(\"h3.s-item__title\"):\n",
    "            summary.append(item.select_one(\"h3.s-item__title\").text)\n",
    "        if item.select_one(\"span.s-item__price\"):\n",
    "            price.append(item.select_one(\"span.s-item__price\").text)\n",
    "\n",
    "    page_num=page_num+1\n",
    "\n",
    "# Check the results\n",
    "print(len(summary))\n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1632 entries, 0 to 1631\n",
      "Data columns (total 2 columns):\n",
      "Summary    1632 non-null object\n",
      "Price      1632 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 25.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sold  Sep 16, 2019$320 REFORMATION WOMEN'S ROM...</td>\n",
       "      <td>$45.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sold  Sep 16, 2019Reformation Florence Skirt S...</td>\n",
       "      <td>$51.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sold  Sep 16, 2019REFORMATION Navy paisley min...</td>\n",
       "      <td>$49.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sold  Sep 16, 2019$78 REFORMATION IRIS RIBBED ...</td>\n",
       "      <td>$49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sold  Sep 16, 2019Reformation Lasker Coat Size...</td>\n",
       "      <td>$66.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary   Price\n",
       "0  Sold  Sep 16, 2019$320 REFORMATION WOMEN'S ROM...  $45.47\n",
       "1  Sold  Sep 16, 2019Reformation Florence Skirt S...  $51.08\n",
       "2  Sold  Sep 16, 2019REFORMATION Navy paisley min...  $49.82\n",
       "3  Sold  Sep 16, 2019$78 REFORMATION IRIS RIBBED ...  $49.99\n",
       "4  Sold  Sep 16, 2019Reformation Lasker Coat Size...  $66.00"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_eBay_ref_df = pd.DataFrame({'Summary': summary, 'Price': price})\n",
    "print(new_eBay_ref_df.info())\n",
    "new_eBay_ref_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-owned listings (brand = Reformation)\n",
    "\n",
    "The scraper is retrieving **sold/completed** listings of **Reformation** brand clothing in **Pre-owned** condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpage = 'https://www.ebay.com/sch/i.html?_nkw=reformation&_sacat=15724&LH_TitleDesc=0&LH_ItemCondition=3000&rt=nc&LH_Sold=1&LH_Complete=1'\n",
    "\n",
    "http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())\n",
    "r = http.request('GET', urlpage)\n",
    "page = urllib.request.urlopen(urlpage).read()\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344\n",
      "1344\n"
     ]
    }
   ],
   "source": [
    "page_num = 1\n",
    "\n",
    "# Create lists to store the scraped information\n",
    "summary = []\n",
    "price = []\n",
    "\n",
    "while page_num<=28: # Only ~1500 listings\n",
    "    html = requests.get(urlpage.format(page_num)).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for item in soup.select('div.s-item__info.clearfix'):\n",
    "        if item.select_one(\"h3.s-item__title\"):\n",
    "            summary.append(item.select_one(\"h3.s-item__title\").text)\n",
    "        if item.select_one(\"span.s-item__price\"):\n",
    "            price.append(item.select_one(\"span.s-item__price\").text)\n",
    "\n",
    "    page_num=page_num+1\n",
    "\n",
    "# Check the results\n",
    "print(len(summary))\n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1344 entries, 0 to 1343\n",
      "Data columns (total 2 columns):\n",
      "Summary    1344 non-null object\n",
      "Price      1344 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 21.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sold  Sep 16, 2019Reformation Grilfriend Colle...</td>\n",
       "      <td>$39.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sold  Sep 16, 2019REFORMATION JEANS Size XS Ri...</td>\n",
       "      <td>$14.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sold  Sep 16, 2019Reformation Bea Skirt (4)</td>\n",
       "      <td>$103.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sold  Sep 15, 2019Reformation York White Linen...</td>\n",
       "      <td>$43.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sold  Sep 15, 2019Reformation Navy Rena Dress ...</td>\n",
       "      <td>$40.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary    Price\n",
       "0  Sold  Sep 16, 2019Reformation Grilfriend Colle...   $39.99\n",
       "1  Sold  Sep 16, 2019REFORMATION JEANS Size XS Ri...   $14.80\n",
       "2        Sold  Sep 16, 2019Reformation Bea Skirt (4)  $103.28\n",
       "3  Sold  Sep 15, 2019Reformation York White Linen...   $43.61\n",
       "4  Sold  Sep 15, 2019Reformation Navy Rena Dress ...   $40.00"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po_eBay_ref_df = pd.DataFrame({'Summary': summary, 'Price': price})\n",
    "print(po_eBay_ref_df.info())\n",
    "po_eBay_ref_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
